; PyCBC configuration for BNS-NSBH-BBH search on Advanced LIGO-Virgo data
;
; Documentation for running the workflow generator is here:
;
;    http://ligo-cbc.github.io/pycbc/releases/v1.2.0/html/workflow/pycbc_make_coinc_search_workflow.html


[workflow]
; http://ligo-cbc.github.io/pycbc/releases/v1.2.0/html/workflow/initialization.html
; file retention level can take 4 possible values 
; "all_files"    for debugging the pipeline
; "all_triggers" recommended for normal running
; "merged_triggers" used to rerun with file reuse for changes that do not affect
;                single-detector trigger sets but may affect coinc results
; "results"      used to rerun with file reuse to rerun with changes to plots
file-retention-level = merged_triggers

[workflow-datafind]
; http://ligo-cbc.github.io/pycbc/releases/v1.2.0/html/workflow/datafind.html
datafind-method = AT_RUNTIME_SINGLE_FRAMES

; Look for times when the segment database says that data is analyzable, but
; no frame data exists on disk. If any frame data is missing, raise an error
datafind-check-segment-gaps = raise_error

; Stat each frame that datafind returns and fail if any frames are missing
datafind-check-frames-exist = raise_error

; Check to see if there are any frames on disk that are not covered in the
; segment_summary table for science segments. This must be "warn" when using
; C00 data, due to known discrepancies between the database segments and GDS
; frames, but should be set to "raise_error" for the final calibration.
;datafind-check-segment-summary = warn

[workflow-segments]
; http://ligo-cbc.github.io/pycbc/releases/v1.2.0/html/workflow/segments.html
segments-method = ALL_SINGLE_IFO_TIME

[workflow-tmpltbank]
; See http://ligo-cbc.github.io/pycbc/releases/v1.2.0/html/workflow/template_bank.html
tmpltbank-method = PREGENERATED_BANK
; NOTE - This bank file may or may not be effectual depending on the data and its PSD!
tmpltbank-pregenerated-bank = https://raw.github.com/ligo-cbc/pycbc-config/7a437f481796ffa57a0cf73caa53a1ee641895ab/O2/bank/H1L1-HYPERBANK_SEOBNRv4v2_VARFLOW_THORNE-1163174417-604800.xml.gz

[workflow-splittable]
; http://ligo-cbc.github.io/pycbc/releases/v1.2.0/html/workflow/splittable.html
splittable-method = IN_WORKFLOW
splittable-exe-tag = splitbank

[workflow-splittable-full_data]
splittable-num-banks = 15

[workflow-splittable-injections]
splittable-num-banks = 15

[workflow-matchedfilter]
; http://ligo-cbc.github.io/pycbc/releases/v1.2.0/html/workflow/matched_filter.html
matchedfilter-method = WORKFLOW_INDEPENDENT_IFOS
min-analysis-segments = 1
min-analysis-length = 528
max-analysis-segments = 10
output-type = hdf
plot-throughput =

[workflow-coincidence]
; http://ligo-cbc.github.io/pycbc/releases/v1.2.0/html/workflow/hdf_coincidence.html
do-trigger-fitting =

[workflow-coincidence-full_data]
; For any given combination of ifos, time shifted coincidences are generated by
; shifting one ifo relative to all the rest
; The shifted ('pivot') ifo will be the one appearing first in this list
timeslide-precedence = H1, L1, V1, K1, I1
parallelization-factor = 1000

[workflow-coincidence-injections]
parallelization-factor = 100

[workflow-psd]
parallelization-factor = 10

;[workflow-gating]
; see gating.ini

[workflow-results]
; number of levels of event hierarchical removal to perform
max-hierarchical-removal = 3

[llwadd]
ilwdchar-compat =

[segments_from_cats]

[ligolw_combine_segments]

[splitbank]
; split the template bank up by chirp mass between jobs for clustering reasons
mchirp-sort =

[inspiral]
; parameters for matched filtering

; amount of buffer data for letting filters settle
pad-data = 8

; conditioning high-pass filter
strain-high-pass = 15

; working sample rate for matched filtering
sample-rate = 2048

; segmentation of the data
; start-pad must be long enough to contain a full BNS signal
segment-length = 512
segment-start-pad = 144
segment-end-pad = 16
; turn on zero-padding
allow-zero-padding =
; Taper the first and last second of data read in for zero padding
taper-data = 1

; estimation of the noise PSD and construction of the whitening filter
psd-estimation = median
psd-segment-length = 16
psd-segment-stride = 8
psd-inverse-length = 16
; 512s PSD length given by:
; 512s = psd-segment-length + (psd-num-segments - 1) * psd-segment-stride
psd-num-segments = 63

; PSD Variation options
psdvar-segment = 8
psdvar-short-segment = 0.25
psdvar-long-segment = 512
psdvar-psd-duration = 8
psdvar-psd-stride = 4
psdvar-low-freq = 20
psdvar-high-freq = 480

; Autogating options
autogating-threshold = 100
autogating-cluster = 0.5
autogating-width = 0.25
autogating-taper = 0.25
autogating-pad = 16

; starting frequency of matched filter integration
; low-frequency-cutoff is set to the minimum variable frequency in the bank,
; rounded down
enable-bank-start-frequency =
low-frequency-cutoff = 20

; template approximant
; switch to SEOBNRv4 templates as soon as we can (M >= 4)
approximant = 'SPAtmplt:mtotal<4' 'SEOBNRv4_ROM:else'
order = -1

; threshold for generating triggers
snr-threshold = 4.0
keep-loudest-interval = 1.072
keep-loudest-num = 100
keep-loudest-log-chirp-window = 0.4

; method for clustering triggers over time
cluster-method = window
cluster-window = 1
cluster-function = symmetric

; signal-based vetoes

; chisq evaluation threshold tuned to avoid bumps in the newsnr distribution
chisq-snr-threshold = 5.25
chisq-bins = "0.72*get_freq('fSEOBNRv4Peak',params.mass1,params.mass2,params.spin1z,params.spin2z)**0.7"
newsnr-threshold = 4.0

; sine-Gaussian chisq
sgchisq-snr-threshold = 6.0
sgchisq-locations = "mtotal>30:20-15,20-30,20-45,20-60,20-75,20-90,20-105,20-120"

; options for reducing the computational cost and storage
filter-inj-only = 
injection-window = 4.5
processing-scheme = mkl

[inspiral-h1]
; Hanford specific matched-filter parameters
channel-name = ${workflow|h1-channel-name}

[inspiral-l1]
; Livingston specific matched-filter parameters
channel-name = ${workflow|l1-channel-name}

[inspiral-v1]
; Virgo specific matched-filter parameters
channel-name = ${workflow|v1-channel-name}

[calculate_psd]
cores = 4
low-frequency-cutoff = ${inspiral|low-frequency-cutoff}
pad-data = ${inspiral|pad-data}
strain-high-pass = ${inspiral|strain-high-pass}
sample-rate = ${inspiral|sample-rate}
segment-length = ${inspiral|segment-length}
segment-start-pad = ${inspiral|segment-start-pad}
segment-end-pad = ${inspiral|segment-end-pad}
psd-estimation = ${inspiral|psd-estimation}
psd-segment-length = ${inspiral|psd-segment-length}
psd-segment-stride = ${inspiral|psd-segment-stride}
psd-num-segments = ${inspiral|psd-num-segments}
taper-data = ${inspiral|taper-data}
autogating-threshold = ${inspiral|autogating-threshold}
autogating-cluster = ${inspiral|autogating-cluster}
autogating-width = ${inspiral|autogating-width}
autogating-taper = ${inspiral|autogating-taper}
autogating-pad = ${inspiral|autogating-pad}

[merge_psds]

[calculate_psd-h1]
channel-name = ${workflow|h1-channel-name}

[calculate_psd-l1]
channel-name = ${workflow|l1-channel-name}

[calculate_psd-v1]
channel-name = ${workflow|v1-channel-name}

[hdf_trigger_merge]

[bank2hdf]

[fit_by_template]
fit-function = exponential
sngl-stat = newsnr_sgveto_psdvar_scaled
stat-threshold = 6.
prune-param = mtotal
log-prune-param =
prune-bins = 2
prune-number = 2

[fit_over_param]
fit-param = template_duration chi_eff eta
; f_low required to calculate template duration to smooth the fit over
f-lower = ${inspiral|low-frequency-cutoff}
log-param = True False False
smoothing-width = 0.4 0.2 0.08

[distribute_background_bins]

[multiifo_coinc]
; additional time (in seconds) to add to light-travel time to construct time coincidence window
; only 2- or multi-ifo coinc times are considered to construct the time shift background ("strict coincidence")
coinc-threshold = 0.002
ranking-statistic = 2ogc
randomize-template-order =
statistic-files = /work/ahnitz/projects/2-ogc/stat/file/t6/statHL.hdf  /work/ahnitz/projects/2-ogc/stat/file/t6/statLV.hdf  /work/ahnitz/projects/2-ogc/stat/file/t6/statHV.hdf  /work/ahnitz/projects/2-ogc/stat/file/t6/statHLV.hdf

[multiifo_coinc-full_data]
; time-slide interval in seconds
timeslide-interval = 0.1
; successive levels of decimation to reduce memory load for background coincs below stated values
loudest-keep-values = 15:10 10:30 5:30 0:30

[multiifo_coinc-fullinj&multiifo_coinc-injfull]
; perform little-dog analysis for software injections
timeslide-interval = ${multiifo_coinc-full_data|timeslide-interval}
cluster-window = ${multiifo_statmap|cluster-window}
; keep only coincs with a stat above specified value in injection little-dog analysis
loudest-keep-values = 15.0:9999999999999

[multiifo_coinc-injinj]

[multiifo_statmap]
max-hierarchical-removal = ${workflow-results|max-hierarchical-removal}
hierarchical-removal-against = exclusive

[multiifo_statmap&multiifo_statmap_inj]
; time window (in seconds) used to remove triggers around zero-lag coincidences
veto-window = 0.100
; cluster each slide separately over a 10 second window
cluster-window = 10.0

[combine_statmap]
cluster-window = ${multiifo_statmap|cluster-window}

[foreground_censor]
